{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9500c71",
   "metadata": {},
   "source": [
    "# Text-Conv Example with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1499739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from softmax import Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f2b2b",
   "metadata": {},
   "source": [
    "### Define CNN model network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6bc4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim=24):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.conv1 = nn.Conv1d(in_channels=16, out_channels=128, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=256, kernel_size=4)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=512, kernel_size=5)\n",
    "        \n",
    "        # flatten and concat conv1, conv2, conv3\n",
    "        self.fc1 = nn.Linear(in_features=(128+256+512), out_features = 256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=2)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (0) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (1) embedding layer (this layer assign a vector to each word index in t)\n",
    "        t = self.embeddings(t)\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        tri_gram = self.conv1(t)\n",
    "        tri_gram = F.relu(tri_gram)\n",
    "        tri_gram = F.max_pool1d(tri_gram, kernel_size=tri_gram.shape[2], stride=1) # GlobalMaxPool1d using MaxPool1d\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        four_gram = self.conv2(t)\n",
    "        four_gram = F.relu(four_gram)\n",
    "        four_gram = F.max_pool1d(four_gram, kernel_size=four_gram.shape[2], stride=1) # GlobalMaxPool1d using MaxPool1d\n",
    "        \n",
    "        # (4) hidden conv layer\n",
    "        five_gram = self.conv3(t)\n",
    "        five_gram = F.relu(five_gram)\n",
    "        five_gram = F.max_pool1d(five_gram, kernel_size=five_gram.shape[2], stride=1) # GlobalMaxPool1d using MaxPool1d\n",
    "        \n",
    "        # flatten and concat conv1, conv2, conv3\n",
    "        t = torch.cat((tri_gram, four_gram, five_gram), dim=1).squeeze(dim=2)\n",
    "        \n",
    "        # (6) hidden linear layer\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (7) output layer\n",
    "        #t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8bd6f5",
   "metadata": {},
   "source": [
    "### Creat CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc079353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CnnModel(\n",
       "  (embeddings): Embedding(1000, 24, padding_idx=0)\n",
       "  (conv1): Conv1d(16, 128, kernel_size=(3,), stride=(1,))\n",
       "  (conv2): Conv1d(16, 256, kernel_size=(4,), stride=(1,))\n",
       "  (conv3): Conv1d(16, 512, kernel_size=(5,), stride=(1,))\n",
       "  (fc1): Linear(in_features=896, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = CnnModel(vocab_size=1000)\n",
    "cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab674c",
   "metadata": {},
   "source": [
    "### Creat random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f11291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creat random word indices in the vocabulary\n",
    "data = torch.randint(0, 1000, (1, 16)) # arguments: start_range=0, end_range=1000, (batch_size, words_in_instance=16)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee10a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[373, 542, 433, 632, 208, 321,   2, 917, 772, 772, 788,  54, 434, 864,\n",
       "         506, 909]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e070ae8",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a818f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basharm\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = cnn_model(data)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe0db32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3469, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][127]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
